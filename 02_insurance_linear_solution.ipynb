{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "02-insurance-linear.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwvicy/zero-to-GANs/blob/master/02_insurance_linear_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "KCWuojrEO-Xq",
        "colab_type": "text"
      },
      "source": [
        "# Insurance cost prediction using linear regression\n",
        "\n",
        "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n",
        "\n",
        "\n",
        "We will create a model with the following steps:\n",
        "1. Download and explore the dataset\n",
        "2. Prepare the dataset for training\n",
        "3. Create a linear regression model\n",
        "4. Train the model to fit the data\n",
        "5. Make predictions using the trained model\n",
        "\n",
        "\n",
        "This assignment builds upon the concepts from the first 2 lectures. It will help to review these Jupyter notebooks:\n",
        "- PyTorch basics: https://jovian.ml/aakashns/01-pytorch-basics\n",
        "- Linear Regression: https://jovian.ml/aakashns/02-linear-regression\n",
        "- Logistic Regression: https://jovian.ml/aakashns/03-logistic-regression\n",
        "- Linear regression (minimal): https://jovian.ml/aakashns/housing-linear-minimal\n",
        "- Logistic regression (minimal): https://jovian.ml/aakashns/mnist-logistic-minimal\n",
        "\n",
        "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N56ipBk7O-Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment and run the commands below if imports fail\n",
        "# !conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
        "# !pip install matplotlib --upgrade --quiet\n",
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMY5MycNO-Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import jovian\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMLQClZFO-X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnsrnQBgO-X8",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Download and explore the data\n",
        "\n",
        "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "Q6ve5lmCO-X9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3b12d07-ccb4-4d36-8094-9ce8e4e7c129"
      },
      "source": [
        "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./insurance.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzdkhOASO-YB",
        "colab_type": "text"
      },
      "source": [
        "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRl5iYH2O-YC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c81992f3-34c0-48de-9c41-df07d601d936"
      },
      "source": [
        "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
        "dataframe_raw.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j0TlqROO-YG",
        "colab_type": "text"
      },
      "source": [
        "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azRBg-ZQO-YH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "your_name = \"vaish\" # at least 5 characters"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmjrSuMSO-YL",
        "colab_type": "text"
      },
      "source": [
        "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LqI4IR4O-YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def customize_dataset(dataframe_raw, rand_str):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    # drop some rows\n",
        "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
        "    # scale input\n",
        "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
        "    # scale target\n",
        "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
        "    # drop column\n",
        "    if ord(rand_str[3]) % 2 == 1:\n",
        "        dataframe = dataframe.drop(['region'], axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2E9cK3MO-YP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "88e36821-d1e5-46b9-c903-315c5868d1e4"
      },
      "source": [
        "dataframe = customize_dataset(dataframe_raw, your_name)\n",
        "dataframe.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>61</td>\n",
              "      <td>male</td>\n",
              "      <td>37.22860</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>13597.574760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>46</td>\n",
              "      <td>male</td>\n",
              "      <td>32.43680</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>8751.319080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>22</td>\n",
              "      <td>female</td>\n",
              "      <td>30.08940</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>37375.369290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>24</td>\n",
              "      <td>male</td>\n",
              "      <td>22.94535</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>2470.616872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "      <td>31.33100</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>10782.933000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex       bmi  children smoker       charges\n",
              "1034   61    male  37.22860         0     no  13597.574760\n",
              "556    46    male  32.43680         1     no   8751.319080\n",
              "1021   22  female  30.08940         3    yes  37375.369290\n",
              "693    24    male  22.94535         0     no   2470.616872\n",
              "403    49    male  31.33100         3     no  10782.933000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT1-IcVoSRPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b97d8ac2-8f60-4a8b-f183-299b49152707"
      },
      "source": [
        "dataframe.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1271, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOQZU2E-O-YS",
        "colab_type": "text"
      },
      "source": [
        "Let us answer some basic questions about the dataset. \n",
        "\n",
        "\n",
        "**Q: How many rows does the dataset have?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk43SGkOO-YT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8042ba0b-bb15-4d22-c044-c9f96733fee4"
      },
      "source": [
        "num_rows = len(dataframe)\n",
        "print(num_rows)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeaVT_NcO-YW",
        "colab_type": "text"
      },
      "source": [
        "**Q: How many columns doe the dataset have**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FuU8SjNO-YX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdcedb82-37db-4ae4-c437-e4b1308581c6"
      },
      "source": [
        "num_cols = len(dataframe.columns)\n",
        "print(num_cols)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIhIyxuqO-Yb",
        "colab_type": "text"
      },
      "source": [
        "**Q: What are the column titles of the input variables?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhhzmhC3O-Yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f45d4652-44d6-4988-84b7-1d1b04f2e264"
      },
      "source": [
        "input_cols = list(dataframe.columns)[:-1]\n",
        "input_cols"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'sex', 'bmi', 'children', 'smoker']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWe8_w6mO-Yf",
        "colab_type": "text"
      },
      "source": [
        "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
        "\n",
        "Hint: `sex` is one of them. List the columns that are not numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBdBQz2GO-Yg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91703895-633c-4aa3-f091-b17b9dd6ff70"
      },
      "source": [
        "categorical_cols = dataframe.select_dtypes('object').columns.tolist()\n",
        "categorical_cols"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sex', 'smoker']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdCYSAuMO-Yj",
        "colab_type": "text"
      },
      "source": [
        "**Q: What are the column titles of output/target variable(s)?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZWQLHINO-Yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97c4785e-613f-47f8-c60f-d26fe50e51f8"
      },
      "source": [
        "output_cols = [dataframe.columns.tolist()[-1]]\n",
        "output_cols"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['charges']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpxK1rFRO-Yp",
        "colab_type": "text"
      },
      "source": [
        "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
        "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_OhZd1AO-Yp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "8f7f89f9-2050-4689-a491-d100641efcfa"
      },
      "source": [
        "# Write your answer here\n",
        "print(f\"Minimum Value of Charge: {dataframe.charges.min()}\")\n",
        "print(f\"Maximum Value of Charge: {dataframe.charges.max()}\")\n",
        "print(f\"Mean Value of Charge: {dataframe.charges.mean()}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.title(\"Values of charge\")\n",
        "sns.distplot(dataframe.charges)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum Value of Charge: 1177.967595\n",
            "Maximum Value of Charge: 66958.9494105\n",
            "Mean Value of Charge: 14041.880828760786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f69840263c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO5UyPkVO-Yt",
        "colab_type": "text"
      },
      "source": [
        "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBG7e8UqO-Yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e50c4814-c59c-49c4-ffc3-7d50f6b16292"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[jovian] Error: Failed to detect Jupyter notebook or Python script. Skipping..\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzyFt7IYO-Yx",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Prepare the dataset for training\n",
        "\n",
        "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZeiU60eO-Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj3Gg0XRO-Y1",
        "colab_type": "text"
      },
      "source": [
        "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe2BA1jhO-Y2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8b595ec2-d25c-4867-a9d4-ac24f29c3c80"
      },
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "inputs_array, targets_array"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[61.     ,  1.     , 37.2286 ,  0.     ,  0.     ],\n",
              "        [46.     ,  1.     , 32.4368 ,  1.     ,  0.     ],\n",
              "        [22.     ,  0.     , 30.0894 ,  3.     ,  1.     ],\n",
              "        ...,\n",
              "        [58.     ,  1.     , 24.41975,  0.     ,  0.     ],\n",
              "        [34.     ,  1.     , 40.8661 ,  2.     ,  0.     ],\n",
              "        [19.     ,  1.     , 29.3425 ,  0.     ,  1.     ]]),\n",
              " array([[13597.57476  ],\n",
              "        [ 8751.31908  ],\n",
              "        [37375.36929  ],\n",
              "        ...,\n",
              "        [12527.6815125],\n",
              "        [ 5380.398135 ],\n",
              "        [34175.757525 ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAnEjiCiO-Y5",
        "colab_type": "text"
      },
      "source": [
        "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKp9aeCaO-Y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = torch.Tensor(inputs_array)\n",
        "targets = torch.Tensor(targets_array)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH6NDFUIO-Y_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef16da6c-0e4c-4e55-b161-a3952c763676"
      },
      "source": [
        "inputs.dtype, targets.dtype"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpG-et5FO-ZE",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz97-XqEO-ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsr69ERNO-ZJ",
        "colab_type": "text"
      },
      "source": [
        "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM5xlQZNO-ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_percent = 0.12 # between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prv4Os9EO-ZQ",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can create data loaders for training & validation.\n",
        "\n",
        "**Q: Pick a batch size for the data loader.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJUrYw5EO-ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6taO2nAmO-ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYZtZqFeO-Ze",
        "colab_type": "text"
      },
      "source": [
        "Let's look at a batch of data to verify everything is working fine so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEvEppZmO-Zf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1392d4af-8389-4d50-d342-c5ad1e4ed2d8"
      },
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[19.0000,  0.0000, 30.8703,  1.0000,  0.0000],\n",
            "        [45.0000,  0.0000, 34.2410,  0.0000,  0.0000],\n",
            "        [61.0000,  0.0000, 24.3276,  0.0000,  0.0000],\n",
            "        [51.0000,  0.0000, 33.0770,  0.0000,  0.0000],\n",
            "        [61.0000,  1.0000, 27.4607,  1.0000,  1.0000],\n",
            "        [61.0000,  1.0000, 32.5289,  0.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 24.9727,  2.0000,  0.0000],\n",
            "        [35.0000,  0.0000, 33.1837,  1.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 33.3971,  0.0000,  0.0000],\n",
            "        [30.0000,  0.0000, 19.3515,  3.0000,  0.0000],\n",
            "        [36.0000,  1.0000, 26.7235,  3.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 27.4607,  0.0000,  1.0000],\n",
            "        [29.0000,  1.0000, 22.2082,  0.0000,  1.0000],\n",
            "        [22.0000,  0.0000, 26.2870,  0.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 30.1670,  0.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 24.9727,  1.0000,  0.0000],\n",
            "        [28.0000,  0.0000, 25.5256,  3.0000,  0.0000],\n",
            "        [25.0000,  1.0000, 32.3301,  2.0000,  1.0000],\n",
            "        [33.0000,  1.0000, 26.6313,  2.0000,  0.0000],\n",
            "        [28.0000,  1.0000, 23.0860,  2.0000,  0.0000],\n",
            "        [46.0000,  1.0000, 32.3447,  1.0000,  0.0000],\n",
            "        [54.0000,  1.0000, 32.6211,  1.0000,  0.0000],\n",
            "        [20.0000,  0.0000, 35.8900,  5.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 24.4440,  0.0000,  0.0000],\n",
            "        [26.0000,  0.0000, 19.2060,  1.0000,  0.0000],\n",
            "        [38.0000,  0.0000, 39.3480,  1.0000,  0.0000],\n",
            "        [59.0000,  1.0000, 35.9870,  1.0000,  0.0000],\n",
            "        [32.0000,  0.0000, 30.5938,  1.0000,  0.0000],\n",
            "        [22.0000,  1.0000, 19.3515,  3.0000,  0.0000],\n",
            "        [60.0000,  1.0000, 32.1167,  3.0000,  0.0000],\n",
            "        [25.0000,  0.0000, 31.2631,  1.0000,  0.0000],\n",
            "        [20.0000,  0.0000, 28.7120,  0.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 31.5153,  0.0000,  1.0000],\n",
            "        [48.0000,  0.0000, 26.4471,  1.0000,  0.0000],\n",
            "        [34.0000,  1.0000, 24.5119,  1.0000,  0.0000],\n",
            "        [47.0000,  0.0000, 34.9200,  1.0000,  0.0000],\n",
            "        [50.0000,  1.0000, 25.8020,  0.0000,  0.0000],\n",
            "        [29.0000,  1.0000, 30.7781,  2.0000,  0.0000],\n",
            "        [35.0000,  1.0000, 33.2904,  3.0000,  0.0000],\n",
            "        [52.0000,  0.0000, 36.3993,  2.0000,  0.0000],\n",
            "        [48.0000,  0.0000, 28.0330,  0.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 22.9890,  0.0000,  0.0000],\n",
            "        [63.0000,  1.0000, 32.6502,  3.0000,  0.0000],\n",
            "        [58.0000,  1.0000, 33.3583,  0.0000,  0.0000],\n",
            "        [50.0000,  1.0000, 30.8703,  0.0000,  1.0000],\n",
            "        [28.0000,  0.0000, 32.3980,  0.0000,  0.0000],\n",
            "        [33.0000,  0.0000, 41.6518,  3.0000,  0.0000],\n",
            "        [25.0000,  1.0000, 23.1830,  5.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 22.0869,  0.0000,  0.0000],\n",
            "        [34.0000,  0.0000, 26.8884,  0.0000,  0.0000],\n",
            "        [32.0000,  1.0000, 32.8054,  1.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 28.1057,  0.0000,  1.0000],\n",
            "        [51.0000,  1.0000, 23.6826,  4.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 35.7445,  0.0000,  0.0000],\n",
            "        [41.0000,  1.0000, 23.2218,  1.0000,  0.0000],\n",
            "        [52.0000,  0.0000, 24.1142,  0.0000,  0.0000],\n",
            "        [44.0000,  1.0000, 28.8430,  2.0000,  0.0000],\n",
            "        [48.0000,  0.0000, 25.0745,  3.0000,  1.0000],\n",
            "        [19.0000,  0.0000, 33.6590,  2.0000,  1.0000],\n",
            "        [42.0000,  0.0000, 25.8020,  0.0000,  1.0000],\n",
            "        [26.0000,  0.0000, 28.7508,  4.0000,  0.0000],\n",
            "        [36.0000,  0.0000, 21.4709,  3.0000,  0.0000],\n",
            "        [45.0000,  0.0000, 24.9290,  3.0000,  0.0000],\n",
            "        [45.0000,  0.0000, 34.7406,  0.0000,  0.0000],\n",
            "        [31.0000,  1.0000, 29.9487,  0.0000,  0.0000],\n",
            "        [61.0000,  1.0000, 22.9454,  0.0000,  0.0000],\n",
            "        [50.0000,  0.0000, 27.3152,  3.0000,  0.0000],\n",
            "        [26.0000,  0.0000, 41.1280,  1.0000,  0.0000],\n",
            "        [47.0000,  0.0000, 43.9604,  1.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 27.4510,  0.0000,  1.0000],\n",
            "        [55.0000,  1.0000, 32.0100,  0.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 23.3673,  1.0000,  0.0000],\n",
            "        [60.0000,  1.0000, 28.7508,  0.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 22.4846,  2.0000,  0.0000],\n",
            "        [49.0000,  0.0000, 26.3549,  0.0000,  0.0000],\n",
            "        [33.0000,  1.0000, 23.8668,  2.0000,  0.0000],\n",
            "        [48.0000,  1.0000, 36.1713,  2.0000,  0.0000],\n",
            "        [47.0000,  1.0000, 37.7718,  2.0000,  1.0000],\n",
            "        [37.0000,  0.0000, 37.2383,  0.0000,  1.0000],\n",
            "        [57.0000,  1.0000, 40.8661,  1.0000,  1.0000],\n",
            "        [50.0000,  0.0000, 27.2764,  3.0000,  0.0000],\n",
            "        [62.0000,  1.0000, 37.6651,  0.0000,  0.0000],\n",
            "        [25.0000,  0.0000, 21.8396,  1.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 23.0375,  2.0000,  0.0000],\n",
            "        [60.0000,  0.0000, 27.8390,  1.0000,  0.0000],\n",
            "        [26.0000,  1.0000, 28.2755,  1.0000,  0.0000],\n",
            "        [54.0000,  1.0000, 38.4120,  1.0000,  0.0000],\n",
            "        [34.0000,  1.0000, 33.6348,  0.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 20.9181,  0.0000,  1.0000],\n",
            "        [32.0000,  0.0000, 23.8620,  0.0000,  1.0000],\n",
            "        [35.0000,  0.0000, 42.0398,  2.0000,  0.0000],\n",
            "        [51.0000,  0.0000, 39.4402,  0.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 28.0330,  0.0000,  0.0000],\n",
            "        [39.0000,  0.0000, 22.1160,  3.0000,  0.0000],\n",
            "        [27.0000,  1.0000, 31.6075,  3.0000,  0.0000],\n",
            "        [28.0000,  0.0000, 25.7147,  2.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 26.7720,  0.0000,  0.0000],\n",
            "        [47.0000,  1.0000, 31.3310,  1.0000,  0.0000],\n",
            "        [45.0000,  1.0000, 35.3856,  2.0000,  1.0000],\n",
            "        [59.0000,  1.0000, 24.6962,  1.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 34.4641,  0.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 26.4616,  3.0000,  1.0000],\n",
            "        [47.0000,  0.0000, 28.6586,  1.0000,  0.0000],\n",
            "        [62.0000,  0.0000, 24.2500,  0.0000,  0.0000],\n",
            "        [35.0000,  0.0000, 34.7406,  1.0000,  0.0000],\n",
            "        [33.0000,  0.0000, 27.4219,  1.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 27.3685,  0.0000,  0.0000],\n",
            "        [62.0000,  1.0000, 26.7235,  1.0000,  0.0000],\n",
            "        [30.0000,  1.0000, 30.6229,  3.0000,  0.0000],\n",
            "        [28.0000,  1.0000, 23.2606,  3.0000,  1.0000],\n",
            "        [34.0000,  0.0000, 22.8532,  0.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 25.9281,  0.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 33.9112,  3.0000,  0.0000],\n",
            "        [20.0000,  1.0000, 31.4231,  1.0000,  0.0000],\n",
            "        [56.0000,  0.0000, 26.3840,  0.0000,  0.0000],\n",
            "        [61.0000,  0.0000, 30.2252,  0.0000,  0.0000],\n",
            "        [20.0000,  1.0000, 34.2507,  1.0000,  0.0000],\n",
            "        [24.0000,  1.0000, 30.1331,  0.0000,  1.0000],\n",
            "        [55.0000,  0.0000, 28.9351,  0.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 34.0955,  0.0000,  0.0000],\n",
            "        [29.0000,  0.0000, 34.4641,  0.0000,  0.0000],\n",
            "        [31.0000,  0.0000, 25.8214,  0.0000,  0.0000],\n",
            "        [63.0000,  1.0000, 21.0102,  1.0000,  0.0000],\n",
            "        [54.0000,  0.0000, 30.3028,  0.0000,  0.0000],\n",
            "        [64.0000,  0.0000, 37.8785,  3.0000,  0.0000],\n",
            "        [44.0000,  1.0000, 35.9870,  2.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 30.0894,  0.0000,  0.0000],\n",
            "        [50.0000,  0.0000, 26.5392,  0.0000,  0.0000]])\n",
            "targets: tensor([[ 2855.2437],\n",
            "        [ 7715.5493],\n",
            "        [25738.7461],\n",
            "        [ 9747.7402],\n",
            "        [30312.0977],\n",
            "        [13800.5039],\n",
            "        [ 3443.8621],\n",
            "        [ 5507.4883],\n",
            "        [ 1194.3431],\n",
            "        [ 5978.1021],\n",
            "        [ 7084.0796],\n",
            "        [18342.4336],\n",
            "        [16945.6992],\n",
            "        [ 2262.0791],\n",
            "        [ 1602.6276],\n",
            "        [ 2846.3699],\n",
            "        [ 5577.7783],\n",
            "        [37930.8008],\n",
            "        [ 5524.5430],\n",
            "        [ 4040.0576],\n",
            "        [ 8751.1807],\n",
            "        [11366.5166],\n",
            "        [ 5072.1616],\n",
            "        [12429.0176],\n",
            "        [ 3547.8555],\n",
            "        [ 6692.2354],\n",
            "        [12964.5303],\n",
            "        [ 5405.9805],\n",
            "        [ 4205.6938],\n",
            "        [14615.8145],\n",
            "        [19129.0703],\n",
            "        [ 1969.1112],\n",
            "        [38743.6680],\n",
            "        [ 9919.6133],\n",
            "        [ 5139.4907],\n",
            "        [ 8984.7520],\n",
            "        [ 8866.6973],\n",
            "        [ 4655.0571],\n",
            "        [ 6231.0986],\n",
            "        [35145.5703],\n",
            "        [ 8691.3994],\n",
            "        [11507.2969],\n",
            "        [15919.6113],\n",
            "        [12331.1309],\n",
            "        [43152.0195],\n",
            "        [ 3330.6189],\n",
            "        [ 6679.0435],\n",
            "        [ 5334.1006],\n",
            "        [12425.4717],\n",
            "        [ 4635.9165],\n",
            "        [ 4685.8579],\n",
            "        [28579.3594],\n",
            "        [12096.1045],\n",
            "        [ 1611.0198],\n",
            "        [ 7201.4038],\n",
            "        [28473.8926],\n",
            "        [33714.0977],\n",
            "        [25389.9805],\n",
            "        [38217.4531],\n",
            "        [22416.1406],\n",
            "        [25905.2461],\n",
            "        [ 7589.6265],\n",
            "        [ 9556.8877],\n",
            "        [ 8118.4507],\n",
            "        [ 4050.6472],\n",
            "        [13786.0840],\n",
            "        [11237.7744],\n",
            "        [ 3580.8401],\n",
            "        [ 8998.3545],\n",
            "        [17935.1348],\n",
            "        [21820.5625],\n",
            "        [ 2311.1519],\n",
            "        [13367.5498],\n",
            "        [15147.3779],\n",
            "        [ 9031.3955],\n",
            "        [ 5520.3833],\n",
            "        [ 9427.0947],\n",
            "        [46412.7852],\n",
            "        [42439.9688],\n",
            "        [51109.2930],\n",
            "        [11639.8662],\n",
            "        [13630.4131],\n",
            "        [ 3773.8794],\n",
            "        [ 3230.9502],\n",
            "        [13885.9277],\n",
            "        [ 3048.0518],\n",
            "        [10973.0801],\n",
            "        [ 4744.7676],\n",
            "        [14435.2656],\n",
            "        [18371.1211],\n",
            "        [ 6139.2637],\n",
            "        [10369.4648],\n",
            "        [ 1830.3748],\n",
            "        [ 8385.1055],\n",
            "        [ 5089.2661],\n",
            "        [ 4557.4629],\n",
            "        [ 1315.0273],\n",
            "        [ 8465.9023],\n",
            "        [44898.5273],\n",
            "        [13559.6924],\n",
            "        [ 1728.7512],\n",
            "        [19134.6230],\n",
            "        [ 9377.4814],\n",
            "        [14123.6777],\n",
            "        [ 5911.9810],\n",
            "        [ 5018.5825],\n",
            "        [12835.5684],\n",
            "        [14634.5498],\n",
            "        [ 5079.4614],\n",
            "        [18546.3008],\n",
            "        [ 5241.9951],\n",
            "        [ 1696.5551],\n",
            "        [ 4689.9526],\n",
            "        [ 2480.3406],\n",
            "        [11626.8350],\n",
            "        [14100.4873],\n",
            "        [29110.5039],\n",
            "        [35966.7578],\n",
            "        [11850.8652],\n",
            "        [ 2241.6465],\n",
            "        [ 3535.0032],\n",
            "        [ 3945.7371],\n",
            "        [15067.3467],\n",
            "        [10855.8779],\n",
            "        [16889.3848],\n",
            "        [ 8127.3540],\n",
            "        [17415.8223],\n",
            "        [26939.4043]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DBDmZixO-Zj",
        "colab_type": "text"
      },
      "source": [
        "Let's save our work by committing to Jovian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MAJ4kL5O-Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTEglFtUO-Zo",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Create a Linear Regression Model\n",
        "\n",
        "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaVoQdrbO-Zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRcvxZLtO-Zu",
        "colab_type": "text"
      },
      "source": [
        "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
        "\n",
        "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK54QprnO-Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear =  nn.Linear(input_size, output_size)                # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                         # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calcuate loss\n",
        "        loss = F.mse_loss(out, targets)                          # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.mse_loss(out, targets)                          # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzY2TAzPO-Z1",
        "colab_type": "text"
      },
      "source": [
        "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H0AQkLRO-Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = InsuranceModel()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_SRdji6O-Z7",
        "colab_type": "text"
      },
      "source": [
        "Let's check out the weights and biases of the model using `model.parameters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYwFQpjdO-Z8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "de7a70f5-0a2f-47d5-90bd-9a45c33a33f5"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.4228,  0.0597,  0.1829,  0.1813, -0.3921]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.0338], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Skj0D_O-aB",
        "colab_type": "text"
      },
      "source": [
        "One final commit before we train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaUF-JStO-aB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQR_Iv0BO-aG",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Train the model to fit the data\n",
        "\n",
        "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cBare-TO-aH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRPnpjKrO-aQ",
        "colab_type": "text"
      },
      "source": [
        "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eWizCpQO-aR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c30134a8-e4a6-45d7-9968-f3ef53f681f2"
      },
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 339802560.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFT4a-zLO-aX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lbJYusMO-aX",
        "colab_type": "text"
      },
      "source": [
        "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
        "\n",
        "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSDBmtsHO-aY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d78b91b0-8985-4342-ebef-65d269189d27"
      },
      "source": [
        "epochs = 2000\n",
        "lr = 1e-5\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 129735648.0000\n",
            "Epoch [40], val_loss: 129560528.0000\n",
            "Epoch [60], val_loss: 129412952.0000\n",
            "Epoch [80], val_loss: 129279248.0000\n",
            "Epoch [100], val_loss: 129144272.0000\n",
            "Epoch [120], val_loss: 129016736.0000\n",
            "Epoch [140], val_loss: 128893848.0000\n",
            "Epoch [160], val_loss: 128782432.0000\n",
            "Epoch [180], val_loss: 128645888.0000\n",
            "Epoch [200], val_loss: 128523312.0000\n",
            "Epoch [220], val_loss: 128404912.0000\n",
            "Epoch [240], val_loss: 128279024.0000\n",
            "Epoch [260], val_loss: 128156464.0000\n",
            "Epoch [280], val_loss: 128034336.0000\n",
            "Epoch [300], val_loss: 127913088.0000\n",
            "Epoch [320], val_loss: 127792896.0000\n",
            "Epoch [340], val_loss: 127675736.0000\n",
            "Epoch [360], val_loss: 127551760.0000\n",
            "Epoch [380], val_loss: 127432192.0000\n",
            "Epoch [400], val_loss: 127310816.0000\n",
            "Epoch [420], val_loss: 127190832.0000\n",
            "Epoch [440], val_loss: 127070992.0000\n",
            "Epoch [460], val_loss: 126952880.0000\n",
            "Epoch [480], val_loss: 126832128.0000\n",
            "Epoch [500], val_loss: 126713456.0000\n",
            "Epoch [520], val_loss: 126594464.0000\n",
            "Epoch [540], val_loss: 126474784.0000\n",
            "Epoch [560], val_loss: 126359440.0000\n",
            "Epoch [580], val_loss: 126239680.0000\n",
            "Epoch [600], val_loss: 126119872.0000\n",
            "Epoch [620], val_loss: 126001328.0000\n",
            "Epoch [640], val_loss: 125889472.0000\n",
            "Epoch [660], val_loss: 125765152.0000\n",
            "Epoch [680], val_loss: 125650312.0000\n",
            "Epoch [700], val_loss: 125531056.0000\n",
            "Epoch [720], val_loss: 125413224.0000\n",
            "Epoch [740], val_loss: 125296272.0000\n",
            "Epoch [760], val_loss: 125179792.0000\n",
            "Epoch [780], val_loss: 125062808.0000\n",
            "Epoch [800], val_loss: 124946128.0000\n",
            "Epoch [820], val_loss: 124830504.0000\n",
            "Epoch [840], val_loss: 124715488.0000\n",
            "Epoch [860], val_loss: 124601168.0000\n",
            "Epoch [880], val_loss: 124482544.0000\n",
            "Epoch [900], val_loss: 124371168.0000\n",
            "Epoch [920], val_loss: 124255032.0000\n",
            "Epoch [940], val_loss: 124146304.0000\n",
            "Epoch [960], val_loss: 124020200.0000\n",
            "Epoch [980], val_loss: 123905256.0000\n",
            "Epoch [1000], val_loss: 123790608.0000\n",
            "Epoch [1020], val_loss: 123681728.0000\n",
            "Epoch [1040], val_loss: 123561088.0000\n",
            "Epoch [1060], val_loss: 123446080.0000\n",
            "Epoch [1080], val_loss: 123336032.0000\n",
            "Epoch [1100], val_loss: 123218368.0000\n",
            "Epoch [1120], val_loss: 123104992.0000\n",
            "Epoch [1140], val_loss: 122996160.0000\n",
            "Epoch [1160], val_loss: 122877344.0000\n",
            "Epoch [1180], val_loss: 122765552.0000\n",
            "Epoch [1200], val_loss: 122651824.0000\n",
            "Epoch [1220], val_loss: 122542144.0000\n",
            "Epoch [1240], val_loss: 122426312.0000\n",
            "Epoch [1260], val_loss: 122313744.0000\n",
            "Epoch [1280], val_loss: 122204696.0000\n",
            "Epoch [1300], val_loss: 122087760.0000\n",
            "Epoch [1320], val_loss: 121976928.0000\n",
            "Epoch [1340], val_loss: 121863328.0000\n",
            "Epoch [1360], val_loss: 121751736.0000\n",
            "Epoch [1380], val_loss: 121642688.0000\n",
            "Epoch [1400], val_loss: 121528096.0000\n",
            "Epoch [1420], val_loss: 121418096.0000\n",
            "Epoch [1440], val_loss: 121308656.0000\n",
            "Epoch [1460], val_loss: 121198896.0000\n",
            "Epoch [1480], val_loss: 121084520.0000\n",
            "Epoch [1500], val_loss: 120976704.0000\n",
            "Epoch [1520], val_loss: 120864160.0000\n",
            "Epoch [1540], val_loss: 120755024.0000\n",
            "Epoch [1560], val_loss: 120641440.0000\n",
            "Epoch [1580], val_loss: 120531664.0000\n",
            "Epoch [1600], val_loss: 120422128.0000\n",
            "Epoch [1620], val_loss: 120312848.0000\n",
            "Epoch [1640], val_loss: 120202568.0000\n",
            "Epoch [1660], val_loss: 120093128.0000\n",
            "Epoch [1680], val_loss: 119986112.0000\n",
            "Epoch [1700], val_loss: 119874432.0000\n",
            "Epoch [1720], val_loss: 119765456.0000\n",
            "Epoch [1740], val_loss: 119656624.0000\n",
            "Epoch [1760], val_loss: 119550992.0000\n",
            "Epoch [1780], val_loss: 119442960.0000\n",
            "Epoch [1800], val_loss: 119335824.0000\n",
            "Epoch [1820], val_loss: 119225872.0000\n",
            "Epoch [1840], val_loss: 119114216.0000\n",
            "Epoch [1860], val_loss: 119006840.0000\n",
            "Epoch [1880], val_loss: 118901608.0000\n",
            "Epoch [1900], val_loss: 118792656.0000\n",
            "Epoch [1920], val_loss: 118682592.0000\n",
            "Epoch [1940], val_loss: 118577760.0000\n",
            "Epoch [1960], val_loss: 118472128.0000\n",
            "Epoch [1980], val_loss: 118362568.0000\n",
            "Epoch [2000], val_loss: 118256880.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e46unipzO-ad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e73ddcc7-973c-49cb-d8d5-ed512accdcb9"
      },
      "source": [
        "epochs = 1500\n",
        "lr = 1e-4\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 117216384.0000\n",
            "Epoch [40], val_loss: 116401712.0000\n",
            "Epoch [60], val_loss: 115404640.0000\n",
            "Epoch [80], val_loss: 115717312.0000\n",
            "Epoch [100], val_loss: 113385520.0000\n",
            "Epoch [120], val_loss: 112489888.0000\n",
            "Epoch [140], val_loss: 111942232.0000\n",
            "Epoch [160], val_loss: 110254304.0000\n",
            "Epoch [180], val_loss: 109577936.0000\n",
            "Epoch [200], val_loss: 108304168.0000\n",
            "Epoch [220], val_loss: 107471072.0000\n",
            "Epoch [240], val_loss: 106485896.0000\n",
            "Epoch [260], val_loss: 106280800.0000\n",
            "Epoch [280], val_loss: 104669968.0000\n",
            "Epoch [300], val_loss: 104458000.0000\n",
            "Epoch [320], val_loss: 103261560.0000\n",
            "Epoch [340], val_loss: 102104704.0000\n",
            "Epoch [360], val_loss: 101380560.0000\n",
            "Epoch [380], val_loss: 100425232.0000\n",
            "Epoch [400], val_loss: 100052520.0000\n",
            "Epoch [420], val_loss: 99251520.0000\n",
            "Epoch [440], val_loss: 98402904.0000\n",
            "Epoch [460], val_loss: 97223760.0000\n",
            "Epoch [480], val_loss: 97189504.0000\n",
            "Epoch [500], val_loss: 96188784.0000\n",
            "Epoch [520], val_loss: 94897920.0000\n",
            "Epoch [540], val_loss: 96534576.0000\n",
            "Epoch [560], val_loss: 93406840.0000\n",
            "Epoch [580], val_loss: 92678016.0000\n",
            "Epoch [600], val_loss: 92675792.0000\n",
            "Epoch [620], val_loss: 91256776.0000\n",
            "Epoch [640], val_loss: 91684432.0000\n",
            "Epoch [660], val_loss: 90371088.0000\n",
            "Epoch [680], val_loss: 89377336.0000\n",
            "Epoch [700], val_loss: 88577968.0000\n",
            "Epoch [720], val_loss: 88160064.0000\n",
            "Epoch [740], val_loss: 88705728.0000\n",
            "Epoch [760], val_loss: 86583624.0000\n",
            "Epoch [780], val_loss: 85909296.0000\n",
            "Epoch [800], val_loss: 85264896.0000\n",
            "Epoch [820], val_loss: 84752928.0000\n",
            "Epoch [840], val_loss: 85190808.0000\n",
            "Epoch [860], val_loss: 83453680.0000\n",
            "Epoch [880], val_loss: 82925184.0000\n",
            "Epoch [900], val_loss: 84065392.0000\n",
            "Epoch [920], val_loss: 83159768.0000\n",
            "Epoch [940], val_loss: 83328400.0000\n",
            "Epoch [960], val_loss: 80634928.0000\n",
            "Epoch [980], val_loss: 80338144.0000\n",
            "Epoch [1000], val_loss: 79403848.0000\n",
            "Epoch [1020], val_loss: 79729088.0000\n",
            "Epoch [1040], val_loss: 78509632.0000\n",
            "Epoch [1060], val_loss: 78251504.0000\n",
            "Epoch [1080], val_loss: 77792160.0000\n",
            "Epoch [1100], val_loss: 78002992.0000\n",
            "Epoch [1120], val_loss: 78963064.0000\n",
            "Epoch [1140], val_loss: 75739600.0000\n",
            "Epoch [1160], val_loss: 75782864.0000\n",
            "Epoch [1180], val_loss: 74945200.0000\n",
            "Epoch [1200], val_loss: 74605312.0000\n",
            "Epoch [1220], val_loss: 74326552.0000\n",
            "Epoch [1240], val_loss: 73350096.0000\n",
            "Epoch [1260], val_loss: 72965080.0000\n",
            "Epoch [1280], val_loss: 72403272.0000\n",
            "Epoch [1300], val_loss: 71991632.0000\n",
            "Epoch [1320], val_loss: 71529872.0000\n",
            "Epoch [1340], val_loss: 71399136.0000\n",
            "Epoch [1360], val_loss: 70952112.0000\n",
            "Epoch [1380], val_loss: 70807400.0000\n",
            "Epoch [1400], val_loss: 69798056.0000\n",
            "Epoch [1420], val_loss: 71434112.0000\n",
            "Epoch [1440], val_loss: 69128928.0000\n",
            "Epoch [1460], val_loss: 68572752.0000\n",
            "Epoch [1480], val_loss: 68459224.0000\n",
            "Epoch [1500], val_loss: 68107848.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLeIOJIdO-ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd859ce0-e0a6-41f3-f1b3-97b5fd469d90"
      },
      "source": [
        "epochs = 4000\n",
        "lr = 1e-6\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 68013064.0000\n",
            "Epoch [40], val_loss: 67977768.0000\n",
            "Epoch [60], val_loss: 67956976.0000\n",
            "Epoch [80], val_loss: 67952104.0000\n",
            "Epoch [100], val_loss: 67949984.0000\n",
            "Epoch [120], val_loss: 67945760.0000\n",
            "Epoch [140], val_loss: 67942920.0000\n",
            "Epoch [160], val_loss: 67941696.0000\n",
            "Epoch [180], val_loss: 67934768.0000\n",
            "Epoch [200], val_loss: 67932672.0000\n",
            "Epoch [220], val_loss: 67932656.0000\n",
            "Epoch [240], val_loss: 67928976.0000\n",
            "Epoch [260], val_loss: 67927136.0000\n",
            "Epoch [280], val_loss: 67919024.0000\n",
            "Epoch [300], val_loss: 67912328.0000\n",
            "Epoch [320], val_loss: 67906096.0000\n",
            "Epoch [340], val_loss: 67904656.0000\n",
            "Epoch [360], val_loss: 67903136.0000\n",
            "Epoch [380], val_loss: 67890608.0000\n",
            "Epoch [400], val_loss: 67894400.0000\n",
            "Epoch [420], val_loss: 67888872.0000\n",
            "Epoch [440], val_loss: 67885184.0000\n",
            "Epoch [460], val_loss: 67875000.0000\n",
            "Epoch [480], val_loss: 67875376.0000\n",
            "Epoch [500], val_loss: 67870744.0000\n",
            "Epoch [520], val_loss: 67858600.0000\n",
            "Epoch [540], val_loss: 67866800.0000\n",
            "Epoch [560], val_loss: 67854456.0000\n",
            "Epoch [580], val_loss: 67849816.0000\n",
            "Epoch [600], val_loss: 67852592.0000\n",
            "Epoch [620], val_loss: 67848992.0000\n",
            "Epoch [640], val_loss: 67844952.0000\n",
            "Epoch [660], val_loss: 67845656.0000\n",
            "Epoch [680], val_loss: 67839208.0000\n",
            "Epoch [700], val_loss: 67833480.0000\n",
            "Epoch [720], val_loss: 67828544.0000\n",
            "Epoch [740], val_loss: 67821528.0000\n",
            "Epoch [760], val_loss: 67821528.0000\n",
            "Epoch [780], val_loss: 67816248.0000\n",
            "Epoch [800], val_loss: 67817576.0000\n",
            "Epoch [820], val_loss: 67808904.0000\n",
            "Epoch [840], val_loss: 67800672.0000\n",
            "Epoch [860], val_loss: 67798080.0000\n",
            "Epoch [880], val_loss: 67798216.0000\n",
            "Epoch [900], val_loss: 67793136.0000\n",
            "Epoch [920], val_loss: 67795720.0000\n",
            "Epoch [940], val_loss: 67784736.0000\n",
            "Epoch [960], val_loss: 67778456.0000\n",
            "Epoch [980], val_loss: 67771920.0000\n",
            "Epoch [1000], val_loss: 67770808.0000\n",
            "Epoch [1020], val_loss: 67771816.0000\n",
            "Epoch [1040], val_loss: 67765072.0000\n",
            "Epoch [1060], val_loss: 67764384.0000\n",
            "Epoch [1080], val_loss: 67762296.0000\n",
            "Epoch [1100], val_loss: 67747240.0000\n",
            "Epoch [1120], val_loss: 67756384.0000\n",
            "Epoch [1140], val_loss: 67753960.0000\n",
            "Epoch [1160], val_loss: 67751704.0000\n",
            "Epoch [1180], val_loss: 67751160.0000\n",
            "Epoch [1200], val_loss: 67736488.0000\n",
            "Epoch [1220], val_loss: 67731936.0000\n",
            "Epoch [1240], val_loss: 67726480.0000\n",
            "Epoch [1260], val_loss: 67720336.0000\n",
            "Epoch [1280], val_loss: 67718288.0000\n",
            "Epoch [1300], val_loss: 67707776.0000\n",
            "Epoch [1320], val_loss: 67708208.0000\n",
            "Epoch [1340], val_loss: 67709936.0000\n",
            "Epoch [1360], val_loss: 67698104.0000\n",
            "Epoch [1380], val_loss: 67699520.0000\n",
            "Epoch [1400], val_loss: 67695888.0000\n",
            "Epoch [1420], val_loss: 67694000.0000\n",
            "Epoch [1440], val_loss: 67687488.0000\n",
            "Epoch [1460], val_loss: 67684568.0000\n",
            "Epoch [1480], val_loss: 67681592.0000\n",
            "Epoch [1500], val_loss: 67681832.0000\n",
            "Epoch [1520], val_loss: 67677008.0000\n",
            "Epoch [1540], val_loss: 67672776.0000\n",
            "Epoch [1560], val_loss: 67666008.0000\n",
            "Epoch [1580], val_loss: 67656680.0000\n",
            "Epoch [1600], val_loss: 67655696.0000\n",
            "Epoch [1620], val_loss: 67652936.0000\n",
            "Epoch [1640], val_loss: 67648424.0000\n",
            "Epoch [1660], val_loss: 67645568.0000\n",
            "Epoch [1680], val_loss: 67645696.0000\n",
            "Epoch [1700], val_loss: 67637120.0000\n",
            "Epoch [1720], val_loss: 67639152.0000\n",
            "Epoch [1740], val_loss: 67628800.0000\n",
            "Epoch [1760], val_loss: 67625416.0000\n",
            "Epoch [1780], val_loss: 67619296.0000\n",
            "Epoch [1800], val_loss: 67606072.0000\n",
            "Epoch [1820], val_loss: 67608096.0000\n",
            "Epoch [1840], val_loss: 67600096.0000\n",
            "Epoch [1860], val_loss: 67599904.0000\n",
            "Epoch [1880], val_loss: 67599216.0000\n",
            "Epoch [1900], val_loss: 67595032.0000\n",
            "Epoch [1920], val_loss: 67597088.0000\n",
            "Epoch [1940], val_loss: 67587472.0000\n",
            "Epoch [1960], val_loss: 67591064.0000\n",
            "Epoch [1980], val_loss: 67587304.0000\n",
            "Epoch [2000], val_loss: 67584352.0000\n",
            "Epoch [2020], val_loss: 67575080.0000\n",
            "Epoch [2040], val_loss: 67570592.0000\n",
            "Epoch [2060], val_loss: 67574232.0000\n",
            "Epoch [2080], val_loss: 67559864.0000\n",
            "Epoch [2100], val_loss: 67559200.0000\n",
            "Epoch [2120], val_loss: 67561184.0000\n",
            "Epoch [2140], val_loss: 67559168.0000\n",
            "Epoch [2160], val_loss: 67549248.0000\n",
            "Epoch [2180], val_loss: 67552928.0000\n",
            "Epoch [2200], val_loss: 67536576.0000\n",
            "Epoch [2220], val_loss: 67536008.0000\n",
            "Epoch [2240], val_loss: 67535896.0000\n",
            "Epoch [2260], val_loss: 67533664.0000\n",
            "Epoch [2280], val_loss: 67532872.0000\n",
            "Epoch [2300], val_loss: 67530328.0000\n",
            "Epoch [2320], val_loss: 67525720.0000\n",
            "Epoch [2340], val_loss: 67517528.0000\n",
            "Epoch [2360], val_loss: 67513600.0000\n",
            "Epoch [2380], val_loss: 67516688.0000\n",
            "Epoch [2400], val_loss: 67509552.0000\n",
            "Epoch [2420], val_loss: 67508136.0000\n",
            "Epoch [2440], val_loss: 67494720.0000\n",
            "Epoch [2460], val_loss: 67483912.0000\n",
            "Epoch [2480], val_loss: 67488528.0000\n",
            "Epoch [2500], val_loss: 67487504.0000\n",
            "Epoch [2520], val_loss: 67480232.0000\n",
            "Epoch [2540], val_loss: 67478608.0000\n",
            "Epoch [2560], val_loss: 67467000.0000\n",
            "Epoch [2580], val_loss: 67466240.0000\n",
            "Epoch [2600], val_loss: 67460200.0000\n",
            "Epoch [2620], val_loss: 67458480.0000\n",
            "Epoch [2640], val_loss: 67452696.0000\n",
            "Epoch [2660], val_loss: 67444496.0000\n",
            "Epoch [2680], val_loss: 67450368.0000\n",
            "Epoch [2700], val_loss: 67450152.0000\n",
            "Epoch [2720], val_loss: 67448912.0000\n",
            "Epoch [2740], val_loss: 67432872.0000\n",
            "Epoch [2760], val_loss: 67431936.0000\n",
            "Epoch [2780], val_loss: 67428112.0000\n",
            "Epoch [2800], val_loss: 67434112.0000\n",
            "Epoch [2820], val_loss: 67424672.0000\n",
            "Epoch [2840], val_loss: 67419400.0000\n",
            "Epoch [2860], val_loss: 67417792.0000\n",
            "Epoch [2880], val_loss: 67413640.0000\n",
            "Epoch [2900], val_loss: 67399968.0000\n",
            "Epoch [2920], val_loss: 67403416.0000\n",
            "Epoch [2940], val_loss: 67398032.0000\n",
            "Epoch [2960], val_loss: 67393400.0000\n",
            "Epoch [2980], val_loss: 67392416.0000\n",
            "Epoch [3000], val_loss: 67389864.0000\n",
            "Epoch [3020], val_loss: 67388408.0000\n",
            "Epoch [3040], val_loss: 67384368.0000\n",
            "Epoch [3060], val_loss: 67373368.0000\n",
            "Epoch [3080], val_loss: 67370528.0000\n",
            "Epoch [3100], val_loss: 67371832.0000\n",
            "Epoch [3120], val_loss: 67368960.0000\n",
            "Epoch [3140], val_loss: 67364272.0000\n",
            "Epoch [3160], val_loss: 67354968.0000\n",
            "Epoch [3180], val_loss: 67347120.0000\n",
            "Epoch [3200], val_loss: 67347160.0000\n",
            "Epoch [3220], val_loss: 67338656.0000\n",
            "Epoch [3240], val_loss: 67336560.0000\n",
            "Epoch [3260], val_loss: 67344464.0000\n",
            "Epoch [3280], val_loss: 67334832.0000\n",
            "Epoch [3300], val_loss: 67333320.0000\n",
            "Epoch [3320], val_loss: 67321744.0000\n",
            "Epoch [3340], val_loss: 67309200.0000\n",
            "Epoch [3360], val_loss: 67317832.0000\n",
            "Epoch [3380], val_loss: 67314008.0000\n",
            "Epoch [3400], val_loss: 67312864.0000\n",
            "Epoch [3420], val_loss: 67301720.0000\n",
            "Epoch [3440], val_loss: 67299912.0000\n",
            "Epoch [3460], val_loss: 67294936.0000\n",
            "Epoch [3480], val_loss: 67295016.0000\n",
            "Epoch [3500], val_loss: 67288768.0000\n",
            "Epoch [3520], val_loss: 67288216.0000\n",
            "Epoch [3540], val_loss: 67288368.0000\n",
            "Epoch [3560], val_loss: 67282672.0000\n",
            "Epoch [3580], val_loss: 67279056.0000\n",
            "Epoch [3600], val_loss: 67268320.0000\n",
            "Epoch [3620], val_loss: 67267176.0000\n",
            "Epoch [3640], val_loss: 67261872.0000\n",
            "Epoch [3660], val_loss: 67267392.0000\n",
            "Epoch [3680], val_loss: 67261728.0000\n",
            "Epoch [3700], val_loss: 67254928.0000\n",
            "Epoch [3720], val_loss: 67244944.0000\n",
            "Epoch [3740], val_loss: 67248448.0000\n",
            "Epoch [3760], val_loss: 67241072.0000\n",
            "Epoch [3780], val_loss: 67237040.0000\n",
            "Epoch [3800], val_loss: 67231056.0000\n",
            "Epoch [3820], val_loss: 67236520.0000\n",
            "Epoch [3840], val_loss: 67228312.0000\n",
            "Epoch [3860], val_loss: 67229696.0000\n",
            "Epoch [3880], val_loss: 67225648.0000\n",
            "Epoch [3900], val_loss: 67211424.0000\n",
            "Epoch [3920], val_loss: 67203856.0000\n",
            "Epoch [3940], val_loss: 67200328.0000\n",
            "Epoch [3960], val_loss: 67204632.0000\n",
            "Epoch [3980], val_loss: 67206464.0000\n",
            "Epoch [4000], val_loss: 67196168.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo9rSnbyO-an",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "970afb12-341a-4a30-b310-7276af086fa7"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 1e-6\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 163124768.0000\n",
            "Epoch [40], val_loss: 135266672.0000\n",
            "Epoch [60], val_loss: 130785136.0000\n",
            "Epoch [80], val_loss: 130027040.0000\n",
            "Epoch [100], val_loss: 129866752.0000\n",
            "Epoch [120], val_loss: 129820040.0000\n",
            "Epoch [140], val_loss: 129793664.0000\n",
            "Epoch [160], val_loss: 129772264.0000\n",
            "Epoch [180], val_loss: 129751664.0000\n",
            "Epoch [200], val_loss: 129733680.0000\n",
            "Epoch [220], val_loss: 129713928.0000\n",
            "Epoch [240], val_loss: 129695184.0000\n",
            "Epoch [260], val_loss: 129677008.0000\n",
            "Epoch [280], val_loss: 129660072.0000\n",
            "Epoch [300], val_loss: 129643264.0000\n",
            "Epoch [320], val_loss: 129626800.0000\n",
            "Epoch [340], val_loss: 129610992.0000\n",
            "Epoch [360], val_loss: 129594120.0000\n",
            "Epoch [380], val_loss: 129578208.0000\n",
            "Epoch [400], val_loss: 129562168.0000\n",
            "Epoch [420], val_loss: 129547520.0000\n",
            "Epoch [440], val_loss: 129531808.0000\n",
            "Epoch [460], val_loss: 129515240.0000\n",
            "Epoch [480], val_loss: 129501632.0000\n",
            "Epoch [500], val_loss: 129485080.0000\n",
            "Epoch [520], val_loss: 129469632.0000\n",
            "Epoch [540], val_loss: 129454560.0000\n",
            "Epoch [560], val_loss: 129440368.0000\n",
            "Epoch [580], val_loss: 129426400.0000\n",
            "Epoch [600], val_loss: 129411240.0000\n",
            "Epoch [620], val_loss: 129396800.0000\n",
            "Epoch [640], val_loss: 129382160.0000\n",
            "Epoch [660], val_loss: 129368224.0000\n",
            "Epoch [680], val_loss: 129355088.0000\n",
            "Epoch [700], val_loss: 129341680.0000\n",
            "Epoch [720], val_loss: 129327216.0000\n",
            "Epoch [740], val_loss: 129313968.0000\n",
            "Epoch [760], val_loss: 129299704.0000\n",
            "Epoch [780], val_loss: 129286448.0000\n",
            "Epoch [800], val_loss: 129272256.0000\n",
            "Epoch [820], val_loss: 129259088.0000\n",
            "Epoch [840], val_loss: 129246176.0000\n",
            "Epoch [860], val_loss: 129232832.0000\n",
            "Epoch [880], val_loss: 129220120.0000\n",
            "Epoch [900], val_loss: 129206944.0000\n",
            "Epoch [920], val_loss: 129194032.0000\n",
            "Epoch [940], val_loss: 129180672.0000\n",
            "Epoch [960], val_loss: 129167488.0000\n",
            "Epoch [980], val_loss: 129154184.0000\n",
            "Epoch [1000], val_loss: 129140624.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7AgTku5O-au",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b711689-9048-4c11-ba6a-8833377c9d55"
      },
      "source": [
        "epochs = 5500\n",
        "lr = 1e-6\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 127298528.0000\n",
            "Epoch [40], val_loss: 127286856.0000\n",
            "Epoch [60], val_loss: 127274880.0000\n",
            "Epoch [80], val_loss: 127262720.0000\n",
            "Epoch [100], val_loss: 127250624.0000\n",
            "Epoch [120], val_loss: 127238744.0000\n",
            "Epoch [140], val_loss: 127226640.0000\n",
            "Epoch [160], val_loss: 127214560.0000\n",
            "Epoch [180], val_loss: 127202576.0000\n",
            "Epoch [200], val_loss: 127191056.0000\n",
            "Epoch [220], val_loss: 127179104.0000\n",
            "Epoch [240], val_loss: 127166704.0000\n",
            "Epoch [260], val_loss: 127154624.0000\n",
            "Epoch [280], val_loss: 127142608.0000\n",
            "Epoch [300], val_loss: 127130624.0000\n",
            "Epoch [320], val_loss: 127118624.0000\n",
            "Epoch [340], val_loss: 127106672.0000\n",
            "Epoch [360], val_loss: 127094704.0000\n",
            "Epoch [380], val_loss: 127082832.0000\n",
            "Epoch [400], val_loss: 127070768.0000\n",
            "Epoch [420], val_loss: 127058800.0000\n",
            "Epoch [440], val_loss: 127046816.0000\n",
            "Epoch [460], val_loss: 127034816.0000\n",
            "Epoch [480], val_loss: 127022848.0000\n",
            "Epoch [500], val_loss: 127010824.0000\n",
            "Epoch [520], val_loss: 126998912.0000\n",
            "Epoch [540], val_loss: 126986976.0000\n",
            "Epoch [560], val_loss: 126975072.0000\n",
            "Epoch [580], val_loss: 126963048.0000\n",
            "Epoch [600], val_loss: 126951040.0000\n",
            "Epoch [620], val_loss: 126939328.0000\n",
            "Epoch [640], val_loss: 126927216.0000\n",
            "Epoch [660], val_loss: 126915264.0000\n",
            "Epoch [680], val_loss: 126903360.0000\n",
            "Epoch [700], val_loss: 126891568.0000\n",
            "Epoch [720], val_loss: 126879872.0000\n",
            "Epoch [740], val_loss: 126867728.0000\n",
            "Epoch [760], val_loss: 126855760.0000\n",
            "Epoch [780], val_loss: 126843760.0000\n",
            "Epoch [800], val_loss: 126831728.0000\n",
            "Epoch [820], val_loss: 126819808.0000\n",
            "Epoch [840], val_loss: 126807968.0000\n",
            "Epoch [860], val_loss: 126796128.0000\n",
            "Epoch [880], val_loss: 126784144.0000\n",
            "Epoch [900], val_loss: 126772176.0000\n",
            "Epoch [920], val_loss: 126760416.0000\n",
            "Epoch [940], val_loss: 126748320.0000\n",
            "Epoch [960], val_loss: 126736400.0000\n",
            "Epoch [980], val_loss: 126724632.0000\n",
            "Epoch [1000], val_loss: 126712640.0000\n",
            "Epoch [1020], val_loss: 126700704.0000\n",
            "Epoch [1040], val_loss: 126688976.0000\n",
            "Epoch [1060], val_loss: 126677032.0000\n",
            "Epoch [1080], val_loss: 126665104.0000\n",
            "Epoch [1100], val_loss: 126653072.0000\n",
            "Epoch [1120], val_loss: 126641208.0000\n",
            "Epoch [1140], val_loss: 126629264.0000\n",
            "Epoch [1160], val_loss: 126617456.0000\n",
            "Epoch [1180], val_loss: 126605448.0000\n",
            "Epoch [1200], val_loss: 126593552.0000\n",
            "Epoch [1220], val_loss: 126581672.0000\n",
            "Epoch [1240], val_loss: 126569904.0000\n",
            "Epoch [1260], val_loss: 126557968.0000\n",
            "Epoch [1280], val_loss: 126546112.0000\n",
            "Epoch [1300], val_loss: 126534448.0000\n",
            "Epoch [1320], val_loss: 126522352.0000\n",
            "Epoch [1340], val_loss: 126510432.0000\n",
            "Epoch [1360], val_loss: 126498624.0000\n",
            "Epoch [1380], val_loss: 126486864.0000\n",
            "Epoch [1400], val_loss: 126474896.0000\n",
            "Epoch [1420], val_loss: 126463048.0000\n",
            "Epoch [1440], val_loss: 126451024.0000\n",
            "Epoch [1460], val_loss: 126439168.0000\n",
            "Epoch [1480], val_loss: 126427328.0000\n",
            "Epoch [1500], val_loss: 126415472.0000\n",
            "Epoch [1520], val_loss: 126403616.0000\n",
            "Epoch [1540], val_loss: 126391792.0000\n",
            "Epoch [1560], val_loss: 126379896.0000\n",
            "Epoch [1580], val_loss: 126368032.0000\n",
            "Epoch [1600], val_loss: 126356160.0000\n",
            "Epoch [1620], val_loss: 126344288.0000\n",
            "Epoch [1640], val_loss: 126332624.0000\n",
            "Epoch [1660], val_loss: 126320712.0000\n",
            "Epoch [1680], val_loss: 126308752.0000\n",
            "Epoch [1700], val_loss: 126296864.0000\n",
            "Epoch [1720], val_loss: 126285072.0000\n",
            "Epoch [1740], val_loss: 126273144.0000\n",
            "Epoch [1760], val_loss: 126261328.0000\n",
            "Epoch [1780], val_loss: 126249584.0000\n",
            "Epoch [1800], val_loss: 126237656.0000\n",
            "Epoch [1820], val_loss: 126225920.0000\n",
            "Epoch [1840], val_loss: 126214104.0000\n",
            "Epoch [1860], val_loss: 126202240.0000\n",
            "Epoch [1880], val_loss: 126190384.0000\n",
            "Epoch [1900], val_loss: 126178656.0000\n",
            "Epoch [1920], val_loss: 126166720.0000\n",
            "Epoch [1940], val_loss: 126154864.0000\n",
            "Epoch [1960], val_loss: 126143024.0000\n",
            "Epoch [1980], val_loss: 126131296.0000\n",
            "Epoch [2000], val_loss: 126119440.0000\n",
            "Epoch [2020], val_loss: 126107632.0000\n",
            "Epoch [2040], val_loss: 126095832.0000\n",
            "Epoch [2060], val_loss: 126083984.0000\n",
            "Epoch [2080], val_loss: 126072128.0000\n",
            "Epoch [2100], val_loss: 126060336.0000\n",
            "Epoch [2120], val_loss: 126048496.0000\n",
            "Epoch [2140], val_loss: 126036704.0000\n",
            "Epoch [2160], val_loss: 126024848.0000\n",
            "Epoch [2180], val_loss: 126013072.0000\n",
            "Epoch [2200], val_loss: 126001360.0000\n",
            "Epoch [2220], val_loss: 125989424.0000\n",
            "Epoch [2240], val_loss: 125977640.0000\n",
            "Epoch [2260], val_loss: 125965792.0000\n",
            "Epoch [2280], val_loss: 125954000.0000\n",
            "Epoch [2300], val_loss: 125942224.0000\n",
            "Epoch [2320], val_loss: 125930384.0000\n",
            "Epoch [2340], val_loss: 125918640.0000\n",
            "Epoch [2360], val_loss: 125906832.0000\n",
            "Epoch [2380], val_loss: 125895056.0000\n",
            "Epoch [2400], val_loss: 125883328.0000\n",
            "Epoch [2420], val_loss: 125871504.0000\n",
            "Epoch [2440], val_loss: 125859616.0000\n",
            "Epoch [2460], val_loss: 125847840.0000\n",
            "Epoch [2480], val_loss: 125836080.0000\n",
            "Epoch [2500], val_loss: 125824272.0000\n",
            "Epoch [2520], val_loss: 125812544.0000\n",
            "Epoch [2540], val_loss: 125800720.0000\n",
            "Epoch [2560], val_loss: 125789088.0000\n",
            "Epoch [2580], val_loss: 125777248.0000\n",
            "Epoch [2600], val_loss: 125765488.0000\n",
            "Epoch [2620], val_loss: 125753792.0000\n",
            "Epoch [2640], val_loss: 125742016.0000\n",
            "Epoch [2660], val_loss: 125730264.0000\n",
            "Epoch [2680], val_loss: 125718512.0000\n",
            "Epoch [2700], val_loss: 125706704.0000\n",
            "Epoch [2720], val_loss: 125695056.0000\n",
            "Epoch [2740], val_loss: 125683120.0000\n",
            "Epoch [2760], val_loss: 125671600.0000\n",
            "Epoch [2780], val_loss: 125659856.0000\n",
            "Epoch [2800], val_loss: 125647936.0000\n",
            "Epoch [2820], val_loss: 125636160.0000\n",
            "Epoch [2840], val_loss: 125624432.0000\n",
            "Epoch [2860], val_loss: 125612648.0000\n",
            "Epoch [2880], val_loss: 125600880.0000\n",
            "Epoch [2900], val_loss: 125589152.0000\n",
            "Epoch [2920], val_loss: 125577440.0000\n",
            "Epoch [2940], val_loss: 125565616.0000\n",
            "Epoch [2960], val_loss: 125553920.0000\n",
            "Epoch [2980], val_loss: 125542208.0000\n",
            "Epoch [3000], val_loss: 125530448.0000\n",
            "Epoch [3020], val_loss: 125518720.0000\n",
            "Epoch [3040], val_loss: 125507072.0000\n",
            "Epoch [3060], val_loss: 125495280.0000\n",
            "Epoch [3080], val_loss: 125483584.0000\n",
            "Epoch [3100], val_loss: 125471840.0000\n",
            "Epoch [3120], val_loss: 125460256.0000\n",
            "Epoch [3140], val_loss: 125448368.0000\n",
            "Epoch [3160], val_loss: 125436624.0000\n",
            "Epoch [3180], val_loss: 125424944.0000\n",
            "Epoch [3200], val_loss: 125413264.0000\n",
            "Epoch [3220], val_loss: 125401552.0000\n",
            "Epoch [3240], val_loss: 125389968.0000\n",
            "Epoch [3260], val_loss: 125378160.0000\n",
            "Epoch [3280], val_loss: 125366464.0000\n",
            "Epoch [3300], val_loss: 125354832.0000\n",
            "Epoch [3320], val_loss: 125343168.0000\n",
            "Epoch [3340], val_loss: 125331408.0000\n",
            "Epoch [3360], val_loss: 125319728.0000\n",
            "Epoch [3380], val_loss: 125308080.0000\n",
            "Epoch [3400], val_loss: 125296368.0000\n",
            "Epoch [3420], val_loss: 125284640.0000\n",
            "Epoch [3440], val_loss: 125272960.0000\n",
            "Epoch [3460], val_loss: 125261264.0000\n",
            "Epoch [3480], val_loss: 125249616.0000\n",
            "Epoch [3500], val_loss: 125237872.0000\n",
            "Epoch [3520], val_loss: 125226208.0000\n",
            "Epoch [3540], val_loss: 125214640.0000\n",
            "Epoch [3560], val_loss: 125202848.0000\n",
            "Epoch [3580], val_loss: 125191208.0000\n",
            "Epoch [3600], val_loss: 125179504.0000\n",
            "Epoch [3620], val_loss: 125167864.0000\n",
            "Epoch [3640], val_loss: 125156192.0000\n",
            "Epoch [3660], val_loss: 125144512.0000\n",
            "Epoch [3680], val_loss: 125132848.0000\n",
            "Epoch [3700], val_loss: 125121128.0000\n",
            "Epoch [3720], val_loss: 125109392.0000\n",
            "Epoch [3740], val_loss: 125097696.0000\n",
            "Epoch [3760], val_loss: 125086128.0000\n",
            "Epoch [3780], val_loss: 125074376.0000\n",
            "Epoch [3800], val_loss: 125062704.0000\n",
            "Epoch [3820], val_loss: 125051056.0000\n",
            "Epoch [3840], val_loss: 125039408.0000\n",
            "Epoch [3860], val_loss: 125027696.0000\n",
            "Epoch [3880], val_loss: 125016032.0000\n",
            "Epoch [3900], val_loss: 125004352.0000\n",
            "Epoch [3920], val_loss: 124992704.0000\n",
            "Epoch [3940], val_loss: 124981088.0000\n",
            "Epoch [3960], val_loss: 124969488.0000\n",
            "Epoch [3980], val_loss: 124957792.0000\n",
            "Epoch [4000], val_loss: 124946320.0000\n",
            "Epoch [4020], val_loss: 124934512.0000\n",
            "Epoch [4040], val_loss: 124922800.0000\n",
            "Epoch [4060], val_loss: 124911168.0000\n",
            "Epoch [4080], val_loss: 124899592.0000\n",
            "Epoch [4100], val_loss: 124887856.0000\n",
            "Epoch [4120], val_loss: 124876464.0000\n",
            "Epoch [4140], val_loss: 124864784.0000\n",
            "Epoch [4160], val_loss: 124852992.0000\n",
            "Epoch [4180], val_loss: 124841344.0000\n",
            "Epoch [4200], val_loss: 124829680.0000\n",
            "Epoch [4220], val_loss: 124818112.0000\n",
            "Epoch [4240], val_loss: 124806512.0000\n",
            "Epoch [4260], val_loss: 124794768.0000\n",
            "Epoch [4280], val_loss: 124783040.0000\n",
            "Epoch [4300], val_loss: 124771440.0000\n",
            "Epoch [4320], val_loss: 124759760.0000\n",
            "Epoch [4340], val_loss: 124748112.0000\n",
            "Epoch [4360], val_loss: 124736512.0000\n",
            "Epoch [4380], val_loss: 124724960.0000\n",
            "Epoch [4400], val_loss: 124713488.0000\n",
            "Epoch [4420], val_loss: 124702000.0000\n",
            "Epoch [4440], val_loss: 124690208.0000\n",
            "Epoch [4460], val_loss: 124678656.0000\n",
            "Epoch [4480], val_loss: 124666928.0000\n",
            "Epoch [4500], val_loss: 124655312.0000\n",
            "Epoch [4520], val_loss: 124643680.0000\n",
            "Epoch [4540], val_loss: 124632120.0000\n",
            "Epoch [4560], val_loss: 124620464.0000\n",
            "Epoch [4580], val_loss: 124608872.0000\n",
            "Epoch [4600], val_loss: 124597360.0000\n",
            "Epoch [4620], val_loss: 124585824.0000\n",
            "Epoch [4640], val_loss: 124574304.0000\n",
            "Epoch [4660], val_loss: 124562704.0000\n",
            "Epoch [4680], val_loss: 124551120.0000\n",
            "Epoch [4700], val_loss: 124539520.0000\n",
            "Epoch [4720], val_loss: 124527960.0000\n",
            "Epoch [4740], val_loss: 124516376.0000\n",
            "Epoch [4760], val_loss: 124504832.0000\n",
            "Epoch [4780], val_loss: 124493200.0000\n",
            "Epoch [4800], val_loss: 124481576.0000\n",
            "Epoch [4820], val_loss: 124470096.0000\n",
            "Epoch [4840], val_loss: 124458416.0000\n",
            "Epoch [4860], val_loss: 124446800.0000\n",
            "Epoch [4880], val_loss: 124435264.0000\n",
            "Epoch [4900], val_loss: 124423728.0000\n",
            "Epoch [4920], val_loss: 124412192.0000\n",
            "Epoch [4940], val_loss: 124400576.0000\n",
            "Epoch [4960], val_loss: 124388992.0000\n",
            "Epoch [4980], val_loss: 124377568.0000\n",
            "Epoch [5000], val_loss: 124366144.0000\n",
            "Epoch [5020], val_loss: 124354416.0000\n",
            "Epoch [5040], val_loss: 124342808.0000\n",
            "Epoch [5060], val_loss: 124331216.0000\n",
            "Epoch [5080], val_loss: 124319696.0000\n",
            "Epoch [5100], val_loss: 124308112.0000\n",
            "Epoch [5120], val_loss: 124296504.0000\n",
            "Epoch [5140], val_loss: 124284952.0000\n",
            "Epoch [5160], val_loss: 124273504.0000\n",
            "Epoch [5180], val_loss: 124261952.0000\n",
            "Epoch [5200], val_loss: 124250496.0000\n",
            "Epoch [5220], val_loss: 124238888.0000\n",
            "Epoch [5240], val_loss: 124227336.0000\n",
            "Epoch [5260], val_loss: 124216016.0000\n",
            "Epoch [5280], val_loss: 124204296.0000\n",
            "Epoch [5300], val_loss: 124192672.0000\n",
            "Epoch [5320], val_loss: 124181088.0000\n",
            "Epoch [5340], val_loss: 124169544.0000\n",
            "Epoch [5360], val_loss: 124158080.0000\n",
            "Epoch [5380], val_loss: 124146592.0000\n",
            "Epoch [5400], val_loss: 124134936.0000\n",
            "Epoch [5420], val_loss: 124123608.0000\n",
            "Epoch [5440], val_loss: 124111992.0000\n",
            "Epoch [5460], val_loss: 124100928.0000\n",
            "Epoch [5480], val_loss: 124089120.0000\n",
            "Epoch [5500], val_loss: 124077392.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfalosxRO-a0",
        "colab_type": "text"
      },
      "source": [
        "**Q: What is the final validation loss of your model?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJJuPC0wO-a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss = 124077392.0000"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz0WPuDaO-a_",
        "colab_type": "text"
      },
      "source": [
        "Let's log the final validation loss to Jovian and commit the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd4_l_nCO-bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5bfc2618-3182-48bd-b61f-e0e66b1a4782"
      },
      "source": [
        "jovian.log_metrics(val_loss=val_loss)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Metrics logged.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFQjfmnOO-bL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d265c7e9-d4dc-466f-c66f-f35fc6da645c"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[jovian] Error: Failed to detect Jupyter notebook or Python script. Skipping..\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKVeG5pRO-bT",
        "colab_type": "text"
      },
      "source": [
        "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhU2xRv6O-bV",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Make predictions using the trained model\n",
        "\n",
        "**Q: Complete the following function definition to make predictions on a single input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPUwSTm3O-bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)              # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "morFdJRdO-bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "803eb0ea-10f8-449c-a024-199b8a3c99d6"
      },
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([34.0000,  1.0000, 29.8760,  0.0000,  1.0000])\n",
            "Target: tensor([37266.2227])\n",
            "Prediction: tensor([13621.3545])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iS_1pELO-bi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "606c9397-d030-490b-936a-172fd8e4c050"
      },
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([42.0000,  1.0000, 23.8668,  2.0000,  1.0000])\n",
            "Target: tensor([22322.3477])\n",
            "Prediction: tensor([14336.5361])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mYvCWgQO-bm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b2c64a1f-4f0a-4e0f-898b-7fde557cb119"
      },
      "source": [
        "input, target = val_ds[23]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([46.0000,  0.0000, 22.9454,  1.0000,  1.0000])\n",
            "Target: tensor([22761.1484])\n",
            "Prediction: tensor([14851.4268])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRbPVYGcO-bs",
        "colab_type": "text"
      },
      "source": [
        "Are you happy with your model's predictions? Try to improve them further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AhNI8KBO-bt",
        "colab_type": "text"
      },
      "source": [
        "## (Optional) Step 6: Try another dataset & blog about it\n",
        "\n",
        "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to clean up & replicate this notebook (or [this one](https://jovian.ml/aakashns/housing-linear-minimal), or [this one](https://jovian.ml/aakashns/mnist-logistic-minimal) ) for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patters in machine learning from problem-specific details.\n",
        "\n",
        "Here are some sources to find good datasets:\n",
        "\n",
        "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
        "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
        "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
        "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
        "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
        "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "\n",
        "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
        "\n",
        "- Interesting title & subtitle\n",
        "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
        "- Downloading & exploring the data\n",
        "- Preparing the data for training\n",
        "- Creating a model using PyTorch\n",
        "- Training the model to fit the data\n",
        "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
        "- Making predictions using the model\n",
        "\n",
        "As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n",
        "\n",
        "Don't forget to share your work on the forum: https://jovian.ml/forum/t/share-your-work-here-assignment-2/4931"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__E2ETUkO-bu",
        "colab_type": "code",
        "colab": {},
        "outputId": "8956acb4-8ad2-4c5e-caa0-3c24ca65f824"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)\n",
        "jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\n",
            "API KEY: ········\n",
            "[jovian] Creating a new project \"aakashns/02-insurance-linear-regression\"\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ml/aakashns/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGEeoF4-O-b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}